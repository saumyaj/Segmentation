{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "#torch.backends.cudnn.enabled = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  187\n"
     ]
    }
   ],
   "source": [
    "manualSeed=187\n",
    "fsize=64\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "\n",
    "torch.cuda.manual_seed_all(manualSeed)\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "dataroot='batched_dataset_64/mat_files/'\n",
    "path=dataroot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.io\n",
    "ls=os.listdir(path)\n",
    "#print ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#xs=[]\n",
    "#ys=[]\n",
    "#for i in ls:\n",
    "    #im1 = scipy.io.loadmat(path+i)\n",
    "    #im1=im1['im']\n",
    "    #xs.append(im1.shape[0])\n",
    "    #ys.append(im1.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "#s1=min(xs)\n",
    "#s2=min(ys)\n",
    "s1=64\n",
    "s2=64\n",
    "print (s1)\n",
    "print (s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imageSize=(s1,s2,3)\n",
    "ls=ls[0:1000]\n",
    "lls=len(ls)\n",
    "import numpy as np\n",
    "X=np.zeros((lls,3,s1,s2))\n",
    "Y=np.zeros((lls,3,s1,s2))\n",
    "count=0\n",
    "import Image\n",
    "for idx,i in enumerate(ls):\n",
    "    li=len(i)\n",
    "    i=i[0:li-4]\n",
    "    im1 = scipy.io.loadmat(path+i+'.mat')\n",
    "    im2=np.asarray(Image.open('batched_dataset_64/image_files/'+i+'.png'))    \n",
    "    im2=im2/255.0;\n",
    "    im1=im1['im']\n",
    "\n",
    "    X[count,0,:,:]=im1[ 0:s1    , 0:s2 ,0]\n",
    "    X[count,1,:,:]=im1[ 0:s1    , 0:s2 ,1]\n",
    "    X[count,2,:,:]=im1[ 0:s1    , 0:s2 ,2]\n",
    "\n",
    "    Y[count,0, 0:s1    , 0:s2 ]=im2[ 0:s1    , 0:s2 ,0]\n",
    "    Y[count,1, 0:s1    , 0:s2 ]=im2[ 0:s1    , 0:s2 ,1]\n",
    "    Y[count,2, 0:s1    , 0:s2 ]=im2[ 0:s1    , 0:s2 ,2]\n",
    "    count=count+1\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 3, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "   \n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#time pass\n",
    "def convert_channels(a):\n",
    "    b=np.zeros((a.shape[1],a.shape[2],3))\n",
    "    b[:,:,0]=a[0,:,:]\n",
    "    b[:,:,1]=a[1,:,:]\n",
    "    b[:,:,2]=a[2,:,:]\n",
    "    return b   \n",
    "\n",
    "def convert_channels2(a):\n",
    "    b=np.zeros((3,a.shape[1],a.shape[2]))\n",
    "    b[0,:,:]=a[:,:,0]\n",
    "    b[1,:,:]=a[:,:,1]\n",
    "    b[2,:,:]=a[:,:,2]\n",
    "    return b   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport scipy.io as sio\\nlx=X.shape[0]\\nimgs=np.zeros(X.shape)\\nfor i in range(lx):\\n    sio.savemat(path+str(i)+'.mat',{'im':X[i,:,:,:]})\\n    a=X[i,:,:,:]\\n    im1_8bit = np.clip(a*255, 0, 255).astype('uint8')\\n    imgs[i,:,:,:]=( im1_8bit)\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import scipy.io as sio\n",
    "lx=X.shape[0]\n",
    "imgs=np.zeros(X.shape)\n",
    "for i in range(lx):\n",
    "    sio.savemat(path+str(i)+'.mat',{'im':X[i,:,:,:]})\n",
    "    a=X[i,:,:,:]\n",
    "    im1_8bit = np.clip(a*255, 0, 255).astype('uint8')\n",
    "    imgs[i,:,:,:]=( im1_8bit)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# save the training set\\npath='batched_hdr/'\\npath2='batched_hdr_tone/'\\nimport scipy.io as sio\\nlx=X.shape[0]\\nfor i in range(lx):\\n    sio.savemat(path+str(i)+'.mat',{'im':X[i,:,:,:]})\\n    see_image(X[i,:,:,:],i,path2)\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# save the training set\n",
    "path='batched_hdr/'\n",
    "path2='batched_hdr_tone/'\n",
    "import scipy.io as sio\n",
    "lx=X.shape[0]\n",
    "for i in range(lx):\n",
    "    sio.savemat(path+str(i)+'.mat',{'im':X[i,:,:,:]})\n",
    "    see_image(X[i,:,:,:],i,path2)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 3, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "print (X.shape)\n",
    "#Z=np.zeros((X.shape[0],3,X.shape[1],X.shape[2]))\n",
    "#Z[:,0,:,:]=X[:,:,:,0]\n",
    "#Z[:,1,:,:]=X[:,:,:,1]\n",
    "#Z[:,2,:,:]=X[:,:,:,2]\n",
    "#X=Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batchSize=10\n",
    "workers=1\n",
    "def get_batch():\n",
    "    import numpy.random\n",
    "    pos=numpy.random.randint(0,X.shape[0],(batchSize))\n",
    "    x1=X[pos]\n",
    "    y1=Y[pos]\n",
    "    return (x1), (y1)\n",
    "\n",
    "\n",
    "\n",
    "ngpu = 1\n",
    "nz = 100\n",
    "ngf = 64\n",
    "ndf = 64\n",
    "nc = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for i in dataloader:\n",
    "#    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#class torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)\n",
    "class _netG(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(_netG, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        model=[]\n",
    "        xx=[]\n",
    "        #model.append(nn.Conv2d(nc, ndf, 3, 2, 0, bias=False))\n",
    "        xx.append(nn.Conv2d(nc, ndf, 3, 1, 1, bias=False))\n",
    "        self.v1=64\n",
    "        model.append(nn.LeakyReLU(0.2, inplace=True) )\n",
    "        model.append(nn.Conv2d(ndf, ndf * 2, 3, 1, 1, bias=False))\n",
    "        #self.bn1=nn.BatchNorm2d(ndf * 2)\n",
    "        model.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "        model.append(nn.Conv2d(ndf * 2, ndf*4, 3, 1, 1, bias=False))\n",
    "        #self.bn2=nn.BatchNorm2d(ndf * 4)\n",
    "        model.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "        model.append(nn.Conv2d(ndf*4, 3, 3, 1, 1, bias=False))\n",
    "        model.append(nn.Sigmoid())\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "        self.xx = nn.Sequential(*xx)\n",
    "        \n",
    "\n",
    "        \n",
    "    def forward(self, input):\n",
    "        #print (input)\n",
    "        op=self.xx(input)\n",
    "        output = self.model(op)\n",
    "\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_netG (\n",
      "  (model): Sequential (\n",
      "    (0): LeakyReLU (0.2, inplace)\n",
      "    (1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (2): LeakyReLU (0.2, inplace)\n",
      "    (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): LeakyReLU (0.2, inplace)\n",
      "    (5): Conv2d(256, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (6): Sigmoid ()\n",
      "  )\n",
      "  (xx): Sequential (\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "netG = _netG(ngpu)\n",
    "netG.apply(weights_init)\n",
    "str_netG=''\n",
    "#str_netG='netG_epoch_1.pth'\n",
    "if str_netG != '':\n",
    "    netG.load_state_dict(torch.load(str_netG))\n",
    "print(netG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.135694012046\n",
      "100 0.185374602675\n",
      "200 0.279772937298\n",
      "300 0.276449739933\n",
      "400 0.149568632245\n",
      "500 0.229862824082\n",
      "600 0.247276470065\n",
      "700 0.162724196911\n",
      "800 0.292690813541\n",
      "900 0.246632367373\n",
      "1000 0.296729564667\n",
      "1100 0.200272843242\n",
      "1200 0.183077558875\n",
      "1300 0.158477306366\n",
      "1400 0.316751658916\n",
      "1500 0.272574931383\n",
      "1600 0.0920715332031\n",
      "1700 0.110912941396\n",
      "1800 0.152114078403\n",
      "1900 0.154284715652\n",
      "2000 0.128168523312\n",
      "2100 0.180111184716\n",
      "2200 0.214414656162\n",
      "2300 0.146823182702\n",
      "2400 0.177805840969\n",
      "2500 0.0849889814854\n",
      "2600 0.208776757121\n",
      "2700 0.272645801306\n",
      "2800 0.209274366498\n",
      "2900 0.297869801521\n",
      "3000 0.20243626833\n",
      "3100 0.231815680861\n",
      "3200 0.234636843204\n",
      "3300 0.131128534675\n",
      "3400 0.0722456499934\n",
      "3500 0.185280352831\n",
      "3600 0.336105912924\n",
      "3700 0.248631179333\n",
      "3800 0.160547286272\n",
      "3900 0.18820720911\n",
      "4000 0.15023213625\n",
      "4100 0.215668991208\n",
      "4200 0.175281584263\n",
      "4300 0.262294888496\n",
      "4400 0.244627520442\n",
      "4500 0.16038608551\n",
      "4600 0.0888355895877\n",
      "4700 0.152383729815\n",
      "4800 0.284998416901\n",
      "4900 0.17831864953\n",
      "5000 0.231642827392\n",
      "5100 0.140858575702\n",
      "5200 0.145898789167\n",
      "5300 0.164892613888\n",
      "5400 0.144342496991\n",
      "5500 0.183145225048\n",
      "5600 0.16793987155\n",
      "5700 0.173399433494\n",
      "5800 0.051877964288\n",
      "5900 0.182461485267\n",
      "6000 0.197668299079\n",
      "6100 0.194153875113\n",
      "6200 0.161428257823\n",
      "6300 0.168189793825\n",
      "6400 0.314303904772\n",
      "6500 0.120502002537\n",
      "6600 0.364221215248\n",
      "6700 0.221713930368\n",
      "6800 0.138974055648\n",
      "6900 0.184631183743\n",
      "7000 0.139773160219\n",
      "7100 0.244020774961\n",
      "7200 0.286816775799\n",
      "7300 0.252376049757\n",
      "7400 0.300921708345\n",
      "7500 0.254766792059\n",
      "7600 0.0980993285775\n",
      "7700 0.233660921454\n",
      "7800 0.273378968239\n",
      "7900 0.202990740538\n",
      "8000 0.0966083630919\n",
      "8100 0.118386469781\n",
      "8200 0.166554242373\n",
      "8300 0.0695997998118\n",
      "8400 0.153187692165\n",
      "8500 0.135464206338\n",
      "8600 0.320152342319\n",
      "8700 0.247634783387\n",
      "8800 0.334581255913\n",
      "8900 0.245775729418\n",
      "9000 0.293491691351\n",
      "9100 0.184081658721\n",
      "9200 0.132760882378\n",
      "9300 0.149139657617\n",
      "9400 0.367023557425\n",
      "9500 0.265726745129\n",
      "9600 0.239693656564\n",
      "9700 0.326320916414\n",
      "9800 0.237904295325\n",
      "9900 0.286774128675\n",
      "10000 0.129934459925\n",
      "10100 0.149975374341\n",
      "10200 0.185060411692\n",
      "10300 0.27002030611\n",
      "10400 0.161218196154\n",
      "10500 0.134719699621\n",
      "10600 0.140999302268\n",
      "10700 0.179708197713\n",
      "10800 0.258609443903\n",
      "10900 0.181600525975\n",
      "11000 0.220862492919\n",
      "11100 0.217517003417\n",
      "11200 0.115355499089\n",
      "11300 0.127668082714\n",
      "11400 0.251333266497\n",
      "11500 0.145659223199\n",
      "11600 0.150908663869\n",
      "11700 0.297422081232\n",
      "11800 0.138421267271\n",
      "11900 0.09892770648\n",
      "12000 0.192970663309\n",
      "12100 0.0567254647613\n",
      "12200 0.255237221718\n",
      "12300 0.152501598001\n",
      "12400 0.214204654098\n",
      "12500 0.162991523743\n",
      "12600 0.172498747706\n",
      "12700 0.210627123713\n",
      "12800 0.225499823689\n",
      "12900 0.118552803993\n",
      "13000 0.346515476704\n",
      "13100 0.116108350456\n",
      "13200 0.144571006298\n",
      "13300 0.156552389264\n",
      "13400 0.0966651812196\n",
      "13500 0.10191322118\n",
      "13600 0.226056441665\n",
      "13700 0.178078755736\n",
      "13800 0.175054892898\n",
      "13900 0.274006962776\n",
      "14000 0.146450668573\n",
      "14100 0.253770232201\n",
      "14200 0.209229752421\n",
      "14300 0.212690606713\n",
      "14400 0.184110581875\n",
      "14500 0.122179389\n",
      "14600 0.133157581091\n",
      "14700 0.215472027659\n",
      "14800 0.329746425152\n",
      "14900 0.151926368475\n",
      "15000 0.23004218936\n",
      "15100 0.295109242201\n",
      "15200 0.14760287106\n",
      "15300 0.126407533884\n",
      "15400 0.196955278516\n",
      "15500 0.274699360132\n",
      "15600 0.165690436959\n",
      "15700 0.228087082505\n",
      "15800 0.22162990272\n",
      "15900 0.164895474911\n",
      "16000 0.10184135288\n",
      "16100 0.194463789463\n",
      "16200 0.212472870946\n",
      "16300 0.213637024164\n",
      "16400 0.248371750116\n",
      "16500 0.20534722507\n",
      "16600 0.18537285924\n",
      "16700 0.232721090317\n",
      "16800 0.189208641648\n",
      "16900 0.087083466351\n",
      "17000 0.173602879047\n",
      "17100 0.119183413684\n",
      "17200 0.175989642739\n",
      "17300 0.164837062359\n",
      "17400 0.197012037039\n",
      "17500 0.203862532973\n",
      "17600 0.16468629241\n",
      "17700 0.133796393871\n",
      "17800 0.296562671661\n",
      "17900 0.110057368875\n",
      "18000 0.279422551394\n",
      "18100 0.116131901741\n",
      "18200 0.232534006238\n",
      "18300 0.146293073893\n",
      "18400 0.39058303833\n",
      "18500 0.222678795457\n",
      "18600 0.314117282629\n",
      "18700 0.123482428491\n",
      "18800 0.240212395787\n",
      "18900 0.249210804701\n",
      "19000 0.163619071245\n",
      "19100 0.131164059043\n",
      "19200 0.240651294589\n",
      "19300 0.235150754452\n",
      "19400 0.20554047823\n",
      "19500 0.186053484678\n",
      "19600 0.13000844419\n",
      "19700 0.228605061769\n",
      "19800 0.204170554876\n",
      "19900 0.212060347199\n",
      "20000 0.152601405978\n",
      "20100 0.22639465332\n",
      "20200 0.213271230459\n",
      "20300 0.209772482514\n",
      "20400 0.220717519522\n",
      "20500 0.229221090674\n",
      "20600 0.116151347756\n",
      "20700 0.244088903069\n",
      "20800 0.275049865246\n",
      "20900 0.186560675502\n",
      "21000 0.298350244761\n",
      "21100 0.203023940325\n",
      "21200 0.253776609898\n",
      "21300 0.1877913028\n",
      "21400 0.194509923458\n",
      "21500 0.146999761462\n",
      "21600 0.177282258868\n",
      "21700 0.157589361072\n",
      "21800 0.168729826808\n",
      "21900 0.21261768043\n",
      "22000 0.182631567121\n",
      "22100 0.220638930798\n",
      "22200 0.229497745633\n",
      "22300 0.13999299705\n",
      "22400 0.235272154212\n",
      "22500 0.242074355483\n",
      "22600 0.209101676941\n",
      "22700 0.352998703718\n",
      "22800 0.129644274712\n",
      "22900 0.311714977026\n",
      "23000 0.211709082127\n",
      "23100 0.28640088439\n",
      "23200 0.138404518366\n",
      "23300 0.263799011707\n",
      "23400 0.172833934426\n",
      "23500 0.212465822697\n",
      "23600 0.142479464412\n",
      "23700 0.284180253744\n",
      "23800 0.350952625275\n",
      "23900 0.214837059379\n",
      "24000 0.146798923612\n",
      "24100 0.17944560945\n",
      "24200 0.187160044909\n",
      "24300 0.350224971771\n",
      "24400 0.30242022872\n",
      "24500 0.159642279148\n",
      "24600 0.188315480947\n",
      "24700 0.223582103848\n",
      "24800 0.326493382454\n",
      "24900 0.145053908229\n",
      "25000 0.199514850974\n",
      "25100 0.242640018463\n",
      "25200 0.0916630104184\n",
      "25300 0.186449587345\n",
      "25400 0.150092735887\n",
      "25500 0.124951988459\n",
      "25600 0.167659714818\n",
      "25700 0.114233635366\n",
      "25800 0.245611816645\n",
      "25900 0.205788955092\n",
      "26000 0.335454434156\n",
      "26100 0.115571603179\n",
      "26200 0.219770163298\n",
      "26300 0.307374954224\n",
      "26400 0.28577837348\n",
      "26500 0.179853647947\n",
      "26600 0.20172534883\n",
      "26700 0.25387224555\n",
      "26800 0.230332300067\n",
      "26900 0.377653777599\n",
      "27000 0.091396972537\n",
      "27100 0.318435639143\n",
      "27200 0.211069330573\n",
      "27300 0.129251226783\n",
      "27400 0.0800582095981\n",
      "27500 0.135465577245\n",
      "27600 0.163130670786\n",
      "27700 0.418800145388\n",
      "27800 0.262022256851\n",
      "27900 0.136719316244\n",
      "28000 0.136253669858\n",
      "28100 0.174697503448\n",
      "28200 0.103099435568\n",
      "28300 0.148434817791\n",
      "28400 0.166617840528\n",
      "28500 0.156214013696\n",
      "28600 0.146350428462\n",
      "28700 0.0898802354932\n",
      "28800 0.282711207867\n",
      "28900 0.114982381463\n",
      "29000 0.30127492547\n",
      "29100 0.117873005569\n",
      "29200 0.274484425783\n",
      "29300 0.134800061584\n",
      "29400 0.20394167304\n",
      "29500 0.160974636674\n",
      "29600 0.23864980042\n",
      "29700 0.143828526139\n",
      "29800 0.149639889598\n",
      "29900 0.255843937397\n",
      "30000 0.132283776999\n",
      "30100 0.194942072034\n",
      "30200 0.216335445642\n",
      "30300 0.268309652805\n",
      "30400 0.0918350890279\n",
      "30500 0.305847734213\n",
      "30600 0.347847372293\n",
      "30700 0.146513909101\n",
      "30800 0.198360234499\n",
      "30900 0.12873904407\n",
      "31000 0.217742621899\n",
      "31100 0.34081441164\n",
      "31200 0.154809102416\n",
      "31300 0.153748378158\n",
      "31400 0.23038135469\n",
      "31500 0.272864758968\n",
      "31600 0.103663161397\n",
      "31700 0.147883325815\n",
      "31800 0.256514191628\n",
      "31900 0.132965102792\n",
      "32000 0.217784449458\n",
      "32100 0.211963713169\n",
      "32200 0.110512919724\n",
      "32300 0.145178154111\n",
      "32400 0.130788132548\n",
      "32500 0.181490600109\n",
      "32600 0.174481421709\n",
      "32700 0.0719436556101\n",
      "32800 0.0838319063187\n",
      "32900 0.206293299794\n",
      "33000 0.140676304698\n",
      "33100 0.420716285706\n",
      "33200 0.22581627965\n",
      "33300 0.148636966944\n",
      "33400 0.186894908547\n",
      "33500 0.305018573999\n",
      "33600 0.150956839323\n",
      "33700 0.181133061647\n",
      "33800 0.259999394417\n",
      "33900 0.156699165702\n",
      "34000 0.102438375354\n",
      "34100 0.121669068933\n",
      "34200 0.22366002202\n",
      "34300 0.12528885901\n",
      "34400 0.166128590703\n",
      "34500 0.0725675523281\n",
      "34600 0.239568606019\n",
      "34700 0.203610286117\n",
      "34800 0.12521879375\n",
      "34900 0.165107741952\n",
      "35000 0.225440323353\n",
      "35100 0.125136166811\n",
      "35200 0.146350696683\n",
      "35300 0.236723840237\n",
      "35400 0.212221473455\n",
      "35500 0.1675388515\n",
      "35600 0.220114305615\n",
      "35700 0.17481186986\n",
      "35800 0.229328483343\n",
      "35900 0.13627769053\n",
      "36000 0.264919042587\n",
      "36100 0.254059493542\n",
      "36200 0.129667550325\n",
      "36300 0.166580349207\n",
      "36400 0.356825739145\n",
      "36500 0.258178383112\n",
      "36600 0.225006967783\n",
      "36700 0.205656811595\n",
      "36800 0.302770912647\n",
      "36900 0.210147365928\n",
      "37000 0.1796977669\n",
      "37100 0.315096974373\n",
      "37200 0.237088397145\n",
      "37300 0.139346510172\n",
      "37400 0.208155974746\n",
      "37500 0.133436247706\n",
      "37600 0.286682218313\n",
      "37700 0.221741870046\n",
      "37800 0.187405616045\n",
      "37900 0.160328418016\n",
      "38000 0.224332988262\n",
      "38100 0.266942292452\n",
      "38200 0.101391643286\n",
      "38300 0.2273825109\n",
      "38400 0.194442853332\n",
      "38500 0.202921390533\n",
      "38600 0.14325723052\n",
      "38700 0.252724200487\n",
      "38800 0.185881718993\n",
      "38900 0.184086620808\n",
      "39000 0.194865167141\n",
      "39100 0.315092623234\n",
      "39200 0.214330300689\n",
      "39300 0.067340798676\n",
      "39400 0.209888592362\n",
      "39500 0.27060469985\n",
      "39600 0.123054243624\n",
      "39700 0.137776002288\n",
      "39800 0.212922543287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39900 0.219248145819\n",
      "40000 0.206449717283\n",
      "40100 0.249788984656\n",
      "40200 0.243732690811\n",
      "40300 0.172553300858\n",
      "40400 0.127497777343\n",
      "40500 0.132267445326\n",
      "40600 0.245131030679\n",
      "40700 0.337338358164\n",
      "40800 0.215449094772\n",
      "40900 0.198129162192\n",
      "41000 0.147881746292\n",
      "41100 0.192114129663\n",
      "41200 0.0531369931996\n",
      "41300 0.229848891497\n",
      "41400 0.165535956621\n",
      "41500 0.161345735192\n",
      "41600 0.205354750156\n",
      "41700 0.251670539379\n",
      "41800 0.167603567243\n",
      "41900 0.263697057962\n",
      "42000 0.314040124416\n",
      "42100 0.11489675194\n",
      "42200 0.301216423512\n",
      "42300 0.232469245791\n",
      "42400 0.232873231173\n",
      "42500 0.179581031203\n",
      "42600 0.184978455305\n",
      "42700 0.188115820289\n",
      "42800 0.284292727709\n",
      "42900 0.195615440607\n",
      "43000 0.191403657198\n",
      "43100 0.357591331005\n",
      "43200 0.235363140702\n",
      "43300 0.128481253982\n",
      "43400 0.162432387471\n",
      "43500 0.11630629003\n",
      "43600 0.186683446169\n",
      "43700 0.127618521452\n",
      "43800 0.164946600795\n",
      "43900 0.199167236686\n",
      "44000 0.188414648175\n",
      "44100 0.284476846457\n",
      "44200 0.151152297854\n",
      "44300 0.164118617773\n",
      "44400 0.189339742064\n",
      "44500 0.129961952567\n",
      "44600 0.246961936355\n",
      "44700 0.325860887766\n",
      "44800 0.189014002681\n",
      "44900 0.188191905618\n",
      "45000 0.186425834894\n",
      "45100 0.255138099194\n",
      "45200 0.140269935131\n",
      "45300 0.276261657476\n",
      "45400 0.279608368874\n",
      "45500 0.263832330704\n",
      "45600 0.207671269774\n",
      "45700 0.249391004443\n",
      "45800 0.115230821073\n",
      "45900 0.243144825101\n",
      "46000 0.334328323603\n",
      "46100 0.176695585251\n",
      "46200 0.126760482788\n",
      "46300 0.274836272001\n",
      "46400 0.147563934326\n",
      "46500 0.149250239134\n",
      "46600 0.253659695387\n",
      "46700 0.172492727637\n",
      "46800 0.177854806185\n",
      "46900 0.157297953963\n",
      "47000 0.215342193842\n",
      "47100 0.133270919323\n",
      "47200 0.357223719358\n",
      "47300 0.232062414289\n",
      "47400 0.228083103895\n",
      "47500 0.151827603579\n",
      "47600 0.25714930892\n",
      "47700 0.175164073706\n",
      "47800 0.268741101027\n",
      "47900 0.161069482565\n",
      "48000 0.0735107436776\n",
      "48100 0.220611125231\n",
      "48200 0.245379701257\n",
      "48300 0.154894128442\n",
      "48400 0.200595647097\n",
      "48500 0.177108943462\n",
      "48600 0.0730628222227\n",
      "48700 0.171910002828\n",
      "48800 0.150294870138\n",
      "48900 0.156343922019\n",
      "49000 0.145959094167\n",
      "49100 0.16986066103\n",
      "49200 0.239489123225\n",
      "49300 0.232427358627\n",
      "49400 0.127780422568\n",
      "49500 0.193074047565\n",
      "49600 0.148575484753\n",
      "49700 0.121018998325\n",
      "49800 0.261380583048\n",
      "49900 0.312629431486\n",
      "50000 0.188886478543\n",
      "50100 0.156531721354\n",
      "50200 0.169771924615\n",
      "50300 0.322453975677\n",
      "50400 0.23284329474\n",
      "50500 0.160888880491\n",
      "50600 0.201080590487\n",
      "50700 0.287489324808\n",
      "50800 0.17477016151\n",
      "50900 0.177457988262\n",
      "51000 0.113576516509\n",
      "51100 0.314315736294\n",
      "51200 0.261261165142\n",
      "51300 0.186980053782\n",
      "51400 0.164522752166\n",
      "51500 0.18305182457\n",
      "51600 0.0964107662439\n",
      "51700 0.201308190823\n",
      "51800 0.200980484486\n",
      "51900 0.191775530577\n",
      "52000 0.181521683931\n",
      "52100 0.146939739585\n",
      "52200 0.137288972735\n",
      "52300 0.252529472113\n",
      "52400 0.0874057859182\n",
      "52500 0.247752904892\n",
      "52600 0.247603908181\n",
      "52700 0.300941437483\n",
      "52800 0.168273031712\n",
      "52900 0.25556230545\n",
      "53000 0.155618920922\n",
      "53100 0.235303714871\n",
      "53200 0.160308673978\n",
      "53300 0.259160101414\n",
      "53400 0.222992226481\n",
      "53500 0.197728127241\n",
      "53600 0.242406561971\n",
      "53700 0.20993603766\n",
      "53800 0.223724409938\n",
      "53900 0.237668901682\n",
      "54000 0.110739640892\n",
      "54100 0.246383905411\n",
      "54200 0.241186082363\n",
      "54300 0.0894924551249\n",
      "54400 0.161783471704\n",
      "54500 0.371679961681\n",
      "54600 0.279094398022\n",
      "54700 0.148262128234\n",
      "54800 0.167644068599\n",
      "54900 0.180535808206\n",
      "55000 0.133126556873\n",
      "55100 0.15890841186\n",
      "55200 0.251001447439\n",
      "55300 0.174490556121\n",
      "55400 0.203087866306\n",
      "55500 0.0983224660158\n",
      "55600 0.19335873425\n",
      "55700 0.227678924799\n",
      "55800 0.238284721971\n"
     ]
    }
   ],
   "source": [
    "cuda=True\n",
    "lr=0.0002\n",
    "beta1=0.5\n",
    "niter=800000\n",
    "outf='output_cnn'\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "input = torch.FloatTensor(batchSize, 3, imageSize[0], imageSize[1])\n",
    "\n",
    "netG.cuda()\n",
    "criterion.cuda()\n",
    "input = input.cuda()\n",
    "input = Variable(input)\n",
    "criterion=nn.MSELoss()\n",
    "criterion.cuda()\n",
    "ss=Y.shape[0]\n",
    "# setup optimizer\n",
    "optimizer = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "import torch.nn\n",
    "for epoch in range(niter):\n",
    "    #print (epoch,1)\n",
    "    data, target = get_batch()\n",
    "    #print (epoch,1)\n",
    "    vam=np.max(data)\n",
    "    vami=np.min(data)\n",
    "    data=data/vam\n",
    "\n",
    "    data, target= torch.from_numpy(data), torch.from_numpy(target)\n",
    "    data, target = data.float().cuda(), target.float().cuda()\n",
    "    data, target = Variable(data), Variable(target)\n",
    "    #optimizer.zero_grad()\n",
    "    #print (data)\n",
    "    #output = netG(data)\n",
    "    #print (output)\n",
    "    #print (target)\n",
    "\n",
    "    #print (output.size())\n",
    "    #print(target.size())\n",
    "    loss = criterion(data, target)\n",
    "    #loss.backward()\n",
    "    #optimizer.step()\n",
    "    #print (epoch,2)\n",
    "    if epoch % 300 == 0:\n",
    "        xyvap=np.random.randint(ss)\n",
    "        #vutils.save_image(Y[xyvap],\n",
    "        #        '%s/real_samples.png' % outf)\n",
    "\n",
    "        ddv=X[xyvap:xyvap+1]\n",
    "        ddv=ddv/np.max(ddv)\n",
    "        ddv=ddv*255\n",
    "        #print (ddv.shape)\n",
    "        ddv2=Variable(torch.from_numpy(ddv).float().cuda())\n",
    "        \n",
    "        ddv3=Y[xyvap:xyvap+1]\n",
    "        ddv3=ddv3*255\n",
    "        #print (ddv.shape)\n",
    "        ddv4=Variable(torch.from_numpy(ddv3).float().cuda())\n",
    "        #print (ddv2)\n",
    "\n",
    "        #fake = netG(ddv2)\n",
    "        #print (fake.data)\n",
    "        #print (ddv4)\n",
    "\n",
    "        vutils.save_image(ddv2.data,\n",
    "                '%s/samples_epoch_%03d.png' % (outf, epoch) , normalize=True)\n",
    "        vutils.save_image(ddv4.data,\n",
    "                '%s/samples_epoch_%03d.png' % (outf, epoch+1), normalize=True)\n",
    "\n",
    "    if(epoch%100==0):\n",
    "        print(epoch,loss.data[0])\n",
    "    if(epoch%1000==0): \n",
    "        torch.save(netG.state_dict(), '%s/netG_epoch_%d.pth' % (outf, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
