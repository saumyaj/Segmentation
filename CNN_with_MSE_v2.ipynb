{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "#torch.backends.cudnn.enabled = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  187\n"
     ]
    }
   ],
   "source": [
    "manualSeed=187\n",
    "fsize=64\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "\n",
    "torch.cuda.manual_seed_all(manualSeed)\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "dataroot='batched_dataset_256/mat_files/'\n",
    "path=dataroot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.io\n",
    "ls=os.listdir(path)\n",
    "#print ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xs=[]\n",
    "ys=[]\n",
    "for i in ls:\n",
    "    im1 = scipy.io.loadmat(path+i)\n",
    "    im1=im1['im']\n",
    "    xs.append(im1.shape[0])\n",
    "    ys.append(im1.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n",
      "256\n"
     ]
    }
   ],
   "source": [
    "s1=min(xs)\n",
    "s2=min(ys)\n",
    "print (s1)\n",
    "print (s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imageSize=(s1,s2,3)\n",
    "lls=len(ls)\n",
    "import numpy as np\n",
    "X=np.zeros((lls,3,s1,s2))\n",
    "Y=np.zeros((lls,3,s1,s2))\n",
    "count=0\n",
    "import Image\n",
    "for idx,i in enumerate(ls):\n",
    "    li=len(i)\n",
    "    i=i[0:li-4]\n",
    "    im1 = scipy.io.loadmat(path+i+'.mat')\n",
    "    im2=np.asarray(Image.open('batched_dataset_256/image_files/'+i+'.png'))    \n",
    "    im2=im2/255.0;\n",
    "    im1=im1['im']\n",
    "\n",
    "    X[count,0,:,:]=im1[ 0:s1    , 0:s2 ,0]\n",
    "    X[count,1,:,:]=im1[ 0:s1    , 0:s2 ,1]\n",
    "    X[count,2,:,:]=im1[ 0:s1    , 0:s2 ,2]\n",
    "\n",
    "    Y[count,0, 0:s1    , 0:s2 ]=im2[ 0:s1    , 0:s2 ,0]\n",
    "    Y[count,1, 0:s1    , 0:s2 ]=im2[ 0:s1    , 0:s2 ,1]\n",
    "    Y[count,2, 0:s1    , 0:s2 ]=im2[ 0:s1    , 0:s2 ,2]\n",
    "    count=count+1\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(474, 3, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "   \n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#time pass\n",
    "def convert_channels(a):\n",
    "    b=np.zeros((a.shape[1],a.shape[2],3))\n",
    "    b[:,:,0]=a[0,:,:]\n",
    "    b[:,:,1]=a[1,:,:]\n",
    "    b[:,:,2]=a[2,:,:]\n",
    "    return b   \n",
    "\n",
    "def convert_channels2(a):\n",
    "    b=np.zeros((3,a.shape[1],a.shape[2]))\n",
    "    b[0,:,:]=a[:,:,0]\n",
    "    b[1,:,:]=a[:,:,1]\n",
    "    b[2,:,:]=a[:,:,2]\n",
    "    return b   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport scipy.io as sio\\nlx=X.shape[0]\\nimgs=np.zeros(X.shape)\\nfor i in range(lx):\\n    sio.savemat(path+str(i)+'.mat',{'im':X[i,:,:,:]})\\n    a=X[i,:,:,:]\\n    im1_8bit = np.clip(a*255, 0, 255).astype('uint8')\\n    imgs[i,:,:,:]=( im1_8bit)\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import scipy.io as sio\n",
    "lx=X.shape[0]\n",
    "imgs=np.zeros(X.shape)\n",
    "for i in range(lx):\n",
    "    sio.savemat(path+str(i)+'.mat',{'im':X[i,:,:,:]})\n",
    "    a=X[i,:,:,:]\n",
    "    im1_8bit = np.clip(a*255, 0, 255).astype('uint8')\n",
    "    imgs[i,:,:,:]=( im1_8bit)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# save the training set\\npath='batched_hdr/'\\npath2='batched_hdr_tone/'\\nimport scipy.io as sio\\nlx=X.shape[0]\\nfor i in range(lx):\\n    sio.savemat(path+str(i)+'.mat',{'im':X[i,:,:,:]})\\n    see_image(X[i,:,:,:],i,path2)\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# save the training set\n",
    "path='batched_hdr/'\n",
    "path2='batched_hdr_tone/'\n",
    "import scipy.io as sio\n",
    "lx=X.shape[0]\n",
    "for i in range(lx):\n",
    "    sio.savemat(path+str(i)+'.mat',{'im':X[i,:,:,:]})\n",
    "    see_image(X[i,:,:,:],i,path2)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(474, 3, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "print (X.shape)\n",
    "#Z=np.zeros((X.shape[0],3,X.shape[1],X.shape[2]))\n",
    "#Z[:,0,:,:]=X[:,:,:,0]\n",
    "#Z[:,1,:,:]=X[:,:,:,1]\n",
    "#Z[:,2,:,:]=X[:,:,:,2]\n",
    "#X=Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batchSize=10\n",
    "workers=1\n",
    "def get_batch():\n",
    "    import numpy.random\n",
    "    pos=numpy.random.randint(0,X.shape[0],(batchSize))\n",
    "    x1=X[pos]\n",
    "    y1=Y[pos]\n",
    "    return (x1), (y1)\n",
    "\n",
    "\n",
    "\n",
    "ngpu = 1\n",
    "nz = 100\n",
    "ngf = 4\n",
    "ndf = 4\n",
    "nc = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for i in dataloader:\n",
    "#    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)\n",
    "#class torch.nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1)\n",
    "class _netG(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(_netG, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        model=[]\n",
    "        xx=[]\n",
    "        #model.append(nn.Conv2d(nc, ndf, 3, 2, 0, bias=False))\n",
    "        xx.append(nn.Conv2d(nc, ndf, 3, 2, 0, bias=False))\n",
    "        self.v1=64\n",
    "\n",
    "        model.append(nn.LeakyReLU(0.2, inplace=True) )\n",
    "        model.append(nn.Conv2d(ndf, ndf * 2, 5, 2, 3, bias=False))\n",
    "        #self.bn1=nn.BatchNorm2d(ndf * 2)\n",
    "        model.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "        model.append(nn.Conv2d(ndf * 2, ndf*4, 5, 2, 1, bias=False))\n",
    "        #self.bn2=nn.BatchNorm2d(ndf * 4)\n",
    "        model.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "        model.append(nn.Conv2d(ndf*4, 3, 5, 2, 3, bias=False))\n",
    "        model.append(nn.Sigmoid())\n",
    "\n",
    "        model2=[]\n",
    "        model2.append(nn.ConvTranspose2d(    3, ngf * 8, 4, 2, 1, bias=False))\n",
    "        model2.append(nn.BatchNorm2d(ngf * 8))\n",
    "        model2.append(nn.ReLU(True))\n",
    "        model2.append(   nn.ConvTranspose2d(ngf * 8, ngf * 2, 3, 2, 1, bias=False))\n",
    "        model2.append(   nn.BatchNorm2d(ngf * 2))\n",
    "        model2.append(  nn.ReLU(True))\n",
    "        # state size. (ngf*2) x 16 x 16\n",
    "        model2.append(   nn.ConvTranspose2d(ngf * 2,     ngf, 3, 2, 1, bias=False))\n",
    "        model2.append(   nn.BatchNorm2d(ngf))\n",
    "        model2.append(  nn.ReLU(True))\n",
    "        \n",
    "        \n",
    "        # state size. (ngf) x 32 x 32\n",
    "        model2.append(  nn.ConvTranspose2d(    ngf,      nc, 3, 2, 1, bias=False))\n",
    "        model2.append(  nn.Tanh())\n",
    "        self.model = nn.Sequential(*model)\n",
    "        self.xx = nn.Sequential(*xx)\n",
    "        self.model2 = nn.Sequential(*model2)\n",
    "        \n",
    "\n",
    "        \n",
    "    def forward(self, input):\n",
    "        #print (input)\n",
    "        op=self.xx(input)\n",
    "        output = self.model(op)\n",
    "        #print (output.size())\n",
    "        #vap=(output.size())\n",
    "        #nnvp=vap[0]*vap[1]*vap[2]*vap[3]\n",
    "    \n",
    "\n",
    "        #output = output.view(-1, nnvp)        \n",
    "        #        print (output,1)\n",
    "\n",
    "        #output=output.transpose(0,1)\n",
    "        #print (output,2)\n",
    "        #va=(input.size())\n",
    "        #print (va)\n",
    "        #print (output.size())\n",
    "        #print (nnvp)\n",
    "        #print (va[0])\n",
    "\n",
    "        #output=output.resize(va[0],int(nnvp/va[0]),1,1)\n",
    "        #      print (output,3)\n",
    "        #self.v1=int(nnvp/va[0])\n",
    "        #print (self.v1)\n",
    "\n",
    "        output=self.model2(output)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_netG (\n",
      "  (model): Sequential (\n",
      "    (0): LeakyReLU (0.2, inplace)\n",
      "    (1): Conv2d(4, 8, kernel_size=(5, 5), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (2): LeakyReLU (0.2, inplace)\n",
      "    (3): Conv2d(8, 16, kernel_size=(5, 5), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): LeakyReLU (0.2, inplace)\n",
      "    (5): Conv2d(16, 3, kernel_size=(5, 5), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (6): Sigmoid ()\n",
      "  )\n",
      "  (xx): Sequential (\n",
      "    (0): Conv2d(3, 4, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "  )\n",
      "  (model2): Sequential (\n",
      "    (0): ConvTranspose2d(3, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): ReLU (inplace)\n",
      "    (3): ConvTranspose2d(32, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (5): ReLU (inplace)\n",
      "    (6): ConvTranspose2d(8, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (8): ReLU (inplace)\n",
      "    (9): ConvTranspose2d(4, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (10): Tanh ()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "netG = _netG(ngpu)\n",
    "netG.apply(weights_init)\n",
    "str_netG=''\n",
    "#str_netG='netG_epoch_1.pth'\n",
    "if str_netG != '':\n",
    "    netG.load_state_dict(torch.load(str_netG))\n",
    "print(netG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "input and target have different number of elements: input[10 x 3 x 265 x 265] has 2106750 elements, while target[10 x 3 x 256 x 256] has 1966080 elements at /b/wheel/pytorch-src/torch/lib/THCUNN/generic/MSECriterion.cu:12",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-ce0ad0c28622>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m#print (output.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m#print(target.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/loss.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0m_assert_no_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mbackend_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbackend_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/_functions/thnn/auto.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         getattr(self._backend, update_output.name)(self._backend.library_state, input, target,\n\u001b[0;32m---> 41\u001b[0;31m                                                    output, *self.additional_args)\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: input and target have different number of elements: input[10 x 3 x 265 x 265] has 2106750 elements, while target[10 x 3 x 256 x 256] has 1966080 elements at /b/wheel/pytorch-src/torch/lib/THCUNN/generic/MSECriterion.cu:12"
     ]
    }
   ],
   "source": [
    "cuda=True\n",
    "lr=0.0002\n",
    "beta1=0.5\n",
    "niter=800000\n",
    "outf='output_256'\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "input = torch.FloatTensor(batchSize, 3, imageSize[0], imageSize[1])\n",
    "\n",
    "netG.cuda()\n",
    "criterion.cuda()\n",
    "input = input.cuda()\n",
    "input = Variable(input)\n",
    "criterion=nn.MSELoss()\n",
    "criterion.cuda()\n",
    "ss=Y.shape[0]\n",
    "# setup optimizer\n",
    "optimizer = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "import torch.nn\n",
    "for epoch in range(niter):\n",
    "    #print (epoch,1)\n",
    "    data, target = get_batch()\n",
    "    #print (epoch,1)\n",
    "\n",
    "    data, target= torch.from_numpy(data), torch.from_numpy(target)\n",
    "    data, target = data.float().cuda(), target.float().cuda()\n",
    "    data, target = Variable(data), Variable(target)\n",
    "    optimizer.zero_grad()\n",
    "    #print (data)\n",
    "    output = netG(data)\n",
    "    #print (output)\n",
    "    #print (target)\n",
    "\n",
    "    #print (output.size())\n",
    "    #print(target.size())\n",
    "    loss = criterion(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    #print (epoch,2)\n",
    "    if epoch % 300 == 0:\n",
    "        xyvap=np.random.randint(ss)\n",
    "        #vutils.save_image(Y[xyvap],\n",
    "        #        '%s/real_samples.png' % outf)\n",
    "\n",
    "        ddv=X[xyvap:xyvap+1]\n",
    "        #print (ddv.shape)\n",
    "        ddv2=Variable(torch.from_numpy(ddv).float().cuda())\n",
    "        \n",
    "        ddv3=Y[xyvap:xyvap+1]\n",
    "        #print (ddv.shape)\n",
    "        ddv4=Variable(torch.from_numpy(ddv3).float().cuda())\n",
    "        #print (ddv2)\n",
    "        fake = netG(ddv2)\n",
    "        #print (fake.data)\n",
    "        #print (ddv4)\n",
    "\n",
    "        vutils.save_image(fake.data,\n",
    "                '%s/samples_epoch_%03d.png' % (outf, epoch) , normalize=False)\n",
    "        vutils.save_image(ddv4.data,\n",
    "                '%s/samples_epoch_%03d.png' % (outf, epoch+1), normalize=False)\n",
    "\n",
    "    if(epoch%100==0):\n",
    "        print(epoch,loss.data[0])\n",
    "    if(epoch%1000==0): \n",
    "        torch.save(netG.state_dict(), '%s/netG_epoch_%d.pth' % (outf, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
