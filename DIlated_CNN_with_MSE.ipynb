{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "#torch.backends.cudnn.enabled = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  187\n"
     ]
    }
   ],
   "source": [
    "manualSeed=187\n",
    "fsize=64\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "\n",
    "torch.cuda.manual_seed_all(manualSeed)\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "dataroot='batched_dataset/mat_files/'\n",
    "path=dataroot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 2] No such file or directory: 'batched_dataset/mat_files/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-6fddabe36bbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#print ls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 2] No such file or directory: 'batched_dataset/mat_files/'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import scipy.io\n",
    "ls=os.listdir(path)\n",
    "#print ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xs=[]\n",
    "ys=[]\n",
    "for i in ls:\n",
    "    im1 = scipy.io.loadmat(path+i)\n",
    "    im1=im1['im']\n",
    "    xs.append(im1.shape[0])\n",
    "    ys.append(im1.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s1=min(xs)\n",
    "s2=min(ys)\n",
    "print (s1)\n",
    "print (s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imageSize=(s1,s2,3)\n",
    "lls=len(ls)\n",
    "import numpy as np\n",
    "X=np.zeros((lls,3,s1,s2))\n",
    "Y=np.zeros((lls,3,128,128))\n",
    "count=0\n",
    "import Image\n",
    "for idx,i in enumerate(ls):\n",
    "    li=len(i)\n",
    "    i=i[0:li-4]\n",
    "    im1 = scipy.io.loadmat(path+i+'.mat')\n",
    "    im2=np.asarray(Image.open('batched_dataset/image_files/'+i+'.png'))    \n",
    "    im2=im2/255.0;\n",
    "    im1=im1['im']\n",
    "\n",
    "    X[count,0,:,:]=im1[ 0:s1    , 0:s2 ,0]\n",
    "    X[count,1,:,:]=im1[ 0:s1    , 0:s2 ,1]\n",
    "    X[count,2,:,:]=im1[ 0:s1    , 0:s2 ,2]\n",
    "\n",
    "    Y[count,0, 0:s1    , 0:s2 ]=im2[ 0:s1    , 0:s2 ,0]\n",
    "    Y[count,1, 0:s1    , 0:s2 ]=im2[ 0:s1    , 0:s2 ,1]\n",
    "    Y[count,2, 0:s1    , 0:s2 ]=im2[ 0:s1    , 0:s2 ,2]\n",
    "    count=count+1\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "   \n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#time pass\n",
    "def convert_channels(a):\n",
    "    b=np.zeros((a.shape[1],a.shape[2],3))\n",
    "    b[:,:,0]=a[0,:,:]\n",
    "    b[:,:,1]=a[1,:,:]\n",
    "    b[:,:,2]=a[2,:,:]\n",
    "    return b   \n",
    "\n",
    "def convert_channels2(a):\n",
    "    b=np.zeros((3,a.shape[1],a.shape[2]))\n",
    "    b[0,:,:]=a[:,:,0]\n",
    "    b[1,:,:]=a[:,:,1]\n",
    "    b[2,:,:]=a[:,:,2]\n",
    "    return b   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "import scipy.io as sio\n",
    "lx=X.shape[0]\n",
    "imgs=np.zeros(X.shape)\n",
    "for i in range(lx):\n",
    "    sio.savemat(path+str(i)+'.mat',{'im':X[i,:,:,:]})\n",
    "    a=X[i,:,:,:]\n",
    "    im1_8bit = np.clip(a*255, 0, 255).astype('uint8')\n",
    "    imgs[i,:,:,:]=( im1_8bit)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# save the training set\n",
    "path='batched_hdr/'\n",
    "path2='batched_hdr_tone/'\n",
    "import scipy.io as sio\n",
    "lx=X.shape[0]\n",
    "for i in range(lx):\n",
    "    sio.savemat(path+str(i)+'.mat',{'im':X[i,:,:,:]})\n",
    "    see_image(X[i,:,:,:],i,path2)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (X.shape)\n",
    "#Z=np.zeros((X.shape[0],3,X.shape[1],X.shape[2]))\n",
    "#Z[:,0,:,:]=X[:,:,:,0]\n",
    "#Z[:,1,:,:]=X[:,:,:,1]\n",
    "#Z[:,2,:,:]=X[:,:,:,2]\n",
    "#X=Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batchSize=10\n",
    "workers=1\n",
    "def get_batch():\n",
    "    import numpy.random\n",
    "    pos=numpy.random.randint(0,X.shape[0],(batchSize))\n",
    "    x1=X[pos]\n",
    "    y1=Y[pos]\n",
    "    return (x1), (y1)\n",
    "\n",
    "\n",
    "\n",
    "ngpu = 1\n",
    "nz = 100\n",
    "ngf = 64\n",
    "ndf = 64\n",
    "nc = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for i in dataloader:\n",
    "#    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#class torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)\n",
    "class _netG(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(_netG, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        model=[]\n",
    "        xx=[]\n",
    "        #model.append(nn.Conv2d(nc, ndf, 3, 2, 0, bias=False))\n",
    "        xx.append(nn.Conv2d(nc, ndf, 3, 2, 0, bias=False))\n",
    "        self.v1=64\n",
    "        \n",
    "        self.conv1 = nn2.SpatialDilatedConvolution(input_nc, ngf, 3, 3,        1 , 1, 1 , 1, 1, 1)\n",
    "        self.conv2 = nn2.SpatialDilatedConvolution(ngf, ngf*2, 3, 3,        1 , 1, 1 , 1  , 2, 2)\n",
    "        self.conv3 = nn2.SpatialDilatedConvolution(ngf*2, ngf*4, 3, 3,        1 , 1, 1 , 1, 3, 3)\n",
    "        self.conv4 = nn2.SpatialDilatedConvolution(ngf*4, 3, 3, 3,        1 , 1, 1 , 1, 3, 3)\n",
    "\n",
    "\n",
    "        model.append(nn.LeakyReLU(0.2, inplace=True) )\n",
    "        model.append(nn.Conv2d(ndf, ndf * 2, 4, 1, 1, bias=False))\n",
    "        #self.bn1=nn.BatchNorm2d(ndf * 2)\n",
    "        model.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "        model.append(nn.Conv2d(ndf * 2, ndf*4, 4, 1, 1, bias=False))\n",
    "        #self.bn2=nn.BatchNorm2d(ndf * 4)\n",
    "        model.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "        model.append(nn.Conv2d(ndf*4, 1, 2, 1, 1, bias=False))\n",
    "        model.append(nn.Sigmoid())\n",
    "\n",
    "        model2=[]\n",
    "        model2.append(nn.ConvTranspose2d(    3844, ngf * 8, 4, 1, 0, bias=False))\n",
    "        model2.append(nn.BatchNorm2d(ngf * 8))\n",
    "        model2.append(nn.ReLU(True))\n",
    "        model2.append( nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False))\n",
    "        model2.append(  nn.BatchNorm2d(ngf * 4))\n",
    "        model2.append(  nn.ReLU(True))\n",
    "        # state size. (ngf*4) x 8 x 8\n",
    "        model2.append(   nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False))\n",
    "        model2.append(   nn.BatchNorm2d(ngf * 2))\n",
    "        model2.append(  nn.ReLU(True))\n",
    "        # state size. (ngf*2) x 16 x 16\n",
    "        model2.append(   nn.ConvTranspose2d(ngf * 2,     ngf, 4, 2, 1, bias=False))\n",
    "        model2.append(   nn.BatchNorm2d(ngf))\n",
    "        model2.append(  nn.ReLU(True))\n",
    "        \n",
    "        model2.append(   nn.ConvTranspose2d(ngf ,     ngf, 4, 2, 1, bias=False))\n",
    "        model2.append(   nn.BatchNorm2d(ngf))\n",
    "        model2.append(  nn.ReLU(True))\n",
    "        \n",
    "        # state size. (ngf) x 32 x 32\n",
    "        model2.append(  nn.ConvTranspose2d(    ngf,      nc, 4, 2, 1, bias=False))\n",
    "        model2.append(  nn.Tanh())\n",
    "        self.model = nn.Sequential(*model)\n",
    "        self.xx = nn.Sequential(*xx)\n",
    "        self.model2 = nn.Sequential(*model2)\n",
    "        \n",
    "\n",
    "        \n",
    "    def forward(self, input):\n",
    "        #print (input)\n",
    "        op=self.xx(input)\n",
    "        output = self.model(op)\n",
    "        #print (output.size())\n",
    "        vap=(output.size())\n",
    "        nnvp=vap[0]*vap[1]*vap[2]*vap[3]\n",
    "    \n",
    "\n",
    "        output = output.view(-1, nnvp)        \n",
    "        #        print (output,1)\n",
    "\n",
    "        output=output.transpose(0,1)\n",
    "        #print (output,2)\n",
    "        va=(input.size())\n",
    "        #print (va)\n",
    "        #print (output.size())\n",
    "        #print (nnvp)\n",
    "        #print (va[0])\n",
    "\n",
    "        output=output.resize(va[0],int(nnvp/va[0]),1,1)\n",
    "        #      print (output,3)\n",
    "        self.v1=int(nnvp/va[0])\n",
    "        #print (self.v1)\n",
    "\n",
    "        output=self.model2(output)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "netG = _netG(ngpu)\n",
    "netG.apply(weights_init)\n",
    "str_netG=''\n",
    "#str_netG='netG_epoch_1.pth'\n",
    "if str_netG != '':\n",
    "    netG.load_state_dict(torch.load(str_netG))\n",
    "print(netG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cuda=True\n",
    "lr=0.0002\n",
    "beta1=0.5\n",
    "niter=800000\n",
    "outf='output'\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "input = torch.FloatTensor(batchSize, 3, imageSize[0], imageSize[1])\n",
    "\n",
    "netG.cuda()\n",
    "criterion.cuda()\n",
    "input = input.cuda()\n",
    "input = Variable(input)\n",
    "criterion=nn.MSELoss()\n",
    "criterion.cuda()\n",
    "ss=Y.shape[0]\n",
    "# setup optimizer\n",
    "optimizer = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "import torch.nn\n",
    "for epoch in range(niter):\n",
    "    #print (epoch,1)\n",
    "    data, target = get_batch()\n",
    "    #print (epoch,1)\n",
    "\n",
    "    data, target= torch.from_numpy(data), torch.from_numpy(target)\n",
    "    data, target = data.float().cuda(), target.float().cuda()\n",
    "    data, target = Variable(data), Variable(target)\n",
    "    optimizer.zero_grad()\n",
    "    #print (data)\n",
    "    output = netG(data)\n",
    "    #print (output)\n",
    "    #print (target)\n",
    "\n",
    "    #print (output.size())\n",
    "    #print(target.size())\n",
    "    loss = criterion(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    #print (epoch,2)\n",
    "    if epoch % 300 == 0:\n",
    "        xyvap=np.random.randint(ss)\n",
    "        #vutils.save_image(Y[xyvap],\n",
    "        #        '%s/real_samples.png' % outf)\n",
    "\n",
    "        ddv=X[xyvap:xyvap+1]\n",
    "        #print (ddv.shape)\n",
    "        ddv2=Variable(torch.from_numpy(ddv).float().cuda())\n",
    "        \n",
    "        ddv3=Y[xyvap:xyvap+1]\n",
    "        #print (ddv.shape)\n",
    "        ddv4=Variable(torch.from_numpy(ddv3).float().cuda())\n",
    "        #print (ddv2)\n",
    "        fake = netG(ddv2)\n",
    "        #print (fake.data)\n",
    "        #print (ddv4)\n",
    "\n",
    "        vutils.save_image(fake.data,\n",
    "                '%s/samples_epoch_%03d.png' % (outf, epoch) , normalize=False)\n",
    "        vutils.save_image(ddv4.data,\n",
    "                '%s/samples_epoch_%03d.png' % (outf, epoch+1), normalize=False)\n",
    "\n",
    "    if(epoch%100==0):\n",
    "        print(epoch,loss.data[0])\n",
    "    if(epoch%1000==0): \n",
    "        torch.save(netG.state_dict(), '%s/netG_epoch_%d.pth' % (outf, epoch))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
